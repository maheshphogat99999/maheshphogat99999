{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WORD EMBEDDING USING WORD2VEC LIBRARY.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI-A_Z3hB5vW"
      },
      "source": [
        "**DIFFERENT WAYS TO GET WORD EMBEDDING**\n",
        "1. Use Pretrained model - Word2Vec, Glove\n",
        "2. Train our own Embedding layer using Word2Vec library\n",
        "3. Train our own Embedding layer using Keras embedding method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzulxLR3CIhz"
      },
      "source": [
        "**2. Train our own Embedding layer using Word2Vec library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-f8ea0CVJN"
      },
      "source": [
        "tokenized_sentences=[['Hello','Mahesh','Welcome','to','word','Embedding'],\n",
        "                     ['Hope','you','are','doing','well'],\n",
        "                     ['Butter', 'is', 'good','for', 'health'],\n",
        "                     ['Today','is','hot','weather']]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2dLTYV1CY_h"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPB0eW5VCa4s"
      },
      "source": [
        "model= Word2Vec(sentences=tokenized_sentences,min_count=1) #Taking all the words which has occured only once"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26u5BPSFCdTA",
        "outputId": "f00ad945-cbdc-410a-e4cb-55bc3e17e2e6"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=19, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD1BvEEMCgeX",
        "outputId": "21eb9468-914c-4125-ec84-4ca174698a8b"
      },
      "source": [
        "words = list(model.wv.vocab)\n",
        "words\n",
        "\n",
        "#words=list(model.wv.index_to_key) In newer version of gensim, vocab is not there\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Mahesh',\n",
              " 'Welcome',\n",
              " 'to',\n",
              " 'word',\n",
              " 'Embedding',\n",
              " 'Hope',\n",
              " 'you',\n",
              " 'are',\n",
              " 'doing',\n",
              " 'well',\n",
              " 'Butter',\n",
              " 'is',\n",
              " 'good',\n",
              " 'for',\n",
              " 'health',\n",
              " 'Today',\n",
              " 'hot',\n",
              " 'weather']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGKpTyZtCiw3",
        "outputId": "20834560-6195-4fc5-8aa4-7715597b987a"
      },
      "source": [
        "#I want to see the vector of training\n",
        "print(model['Welcome']) #The word training has been rated on 100 different features\n",
        "#Encoded value for the word \"Welcome\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3.7650601e-03 -1.2179224e-03 -4.2425847e-04 -8.9386239e-04\n",
            "  2.1250078e-03  3.8709927e-03  2.7244866e-03 -2.5924814e-05\n",
            "  6.1725947e-04  3.1192394e-03  4.6339417e-03 -3.8614331e-03\n",
            "  2.5257054e-03  4.0875631e-03  1.4241303e-03  2.0040891e-03\n",
            " -1.2782528e-03 -4.3493896e-03  3.5739685e-03  1.5832009e-04\n",
            " -3.1627368e-03 -7.0243684e-04 -4.1268443e-04  2.2434241e-03\n",
            " -4.3932437e-03  3.9895754e-03 -1.9408502e-03  1.0702274e-03\n",
            " -2.5505740e-03 -9.4581617e-04  1.6238312e-03  1.1948169e-03\n",
            " -1.1103308e-03  2.7468204e-03 -4.8664892e-03 -7.2940061e-04\n",
            "  1.5076114e-03  2.6693153e-03 -3.9647511e-04  9.2143040e-05\n",
            " -2.3899819e-03 -2.4591095e-03 -2.4214603e-06  1.1295952e-03\n",
            " -1.6421850e-03 -3.0808675e-03  4.9064187e-03  1.7273466e-03\n",
            " -4.1975162e-04  1.9720905e-03 -2.1403860e-03 -4.1825376e-03\n",
            " -3.5133825e-03 -4.0898267e-03  2.9074191e-04 -3.2694489e-03\n",
            " -3.1641005e-03  2.0034814e-03 -4.3100727e-06 -4.5858743e-03\n",
            " -6.1535969e-04  9.4023708e-04 -4.8876232e-03 -1.8397727e-03\n",
            "  1.5647954e-03 -4.6435394e-03  4.1341982e-03 -4.9538659e-03\n",
            " -8.7725854e-04 -2.1008025e-03  8.3189353e-04  4.9844063e-03\n",
            "  3.4482570e-03  3.3542996e-03 -2.6104797e-03  1.9626757e-03\n",
            "  1.0195816e-03 -3.4388052e-03 -3.6357515e-03 -7.0902350e-04\n",
            "  7.7371852e-04 -4.4777668e-03 -3.3650905e-04  8.4525603e-04\n",
            " -3.8572145e-03  1.0143634e-03  4.2238610e-04  2.5650987e-03\n",
            " -2.6272796e-03 -4.8280451e-03  4.3526869e-03  3.0906531e-03\n",
            "  4.7034649e-03  2.8215160e-03  9.2348950e-05  3.7035770e-03\n",
            "  2.7836449e-03 -2.3592648e-03  9.5131242e-04 -4.3947585e-03]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sm6XdltC7oa"
      },
      "source": [
        "## AS THE WORD \"World\" is not there in our vocabulary, Thus it will show error here\n",
        "print(model['World']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqaiY0NDDG4l",
        "outputId": "487cfc48-a5aa-4f61-f9b6-5b334297e288"
      },
      "source": [
        "model.most_similar('Hello') #the vector of Hello is compared with all other words"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('you', 0.12667392194271088),\n",
              " ('is', 0.10743431746959686),\n",
              " ('for', 0.08030496537685394),\n",
              " ('doing', 0.07783336192369461),\n",
              " ('Today', 0.06990745663642883),\n",
              " ('well', 0.05721601843833923),\n",
              " ('health', 0.0514802522957325),\n",
              " ('Mahesh', 0.051442719995975494),\n",
              " ('Welcome', 0.020477555692195892),\n",
              " ('Embedding', 0.005391038954257965)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGceOcFvEHvD"
      },
      "source": [
        "model.most_similar('Apple') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGe6boqeDdRy"
      },
      "source": [
        "### ** TAKE AWAY FROM ABOVE. Here there is BIG LIMITATION** When we train our model by our own from scratch, the Model is not able to identify any new word like as mentioned \"Apple\". Because it is not there in our mentioned library.  Thus, it is the disadvantage of when we train our own network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHIjAVbbEovE"
      },
      "source": [
        "**3. Train our own Embedding layer using Keras embedding method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHRMmhvkEiTu"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-u9JlOBEw0V"
      },
      "source": [
        "#Define your own documents\n",
        "sentences = ['This is a great product', \n",
        "             'Mobile is awesome machine',\n",
        "             'It is beyond expectation',\n",
        "             'Battery is insane',\n",
        "             'Display is not good']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoKN2EbXE5Z0"
      },
      "source": [
        "sent_labels = array([1,1,1,0,0])  # Positive sentences are assigned:1, and Negative are assigned:0"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFKDvzXjE7V4",
        "outputId": "0a8bb8a4-309d-4aee-c29b-0c190fe1af4d"
      },
      "source": [
        "vocab_size = 50 #Is it dimension?\n",
        "encoded_sent = [one_hot(i,vocab_size)for i in sentences]\n",
        "encoded_sent"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[29, 35, 15, 36, 40],\n",
              " [32, 35, 31, 20],\n",
              " [26, 35, 23, 47],\n",
              " [20, 35, 14],\n",
              " [19, 35, 22, 44]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CESb9BAqFAEz",
        "outputId": "7eb8b082-e8dc-40f3-a80e-afe7b34ffd3b"
      },
      "source": [
        "# Now I want to train my Neural Network, Thus, the size of the vector should be same. THUS APPLYING PADDING\n",
        "# Padding aage add kardega, \"padding=post\" doge toh piche zeros add kardega\n",
        "padded_sent = pad_sequences(encoded_sent,maxlen = 6,padding='pre')\n",
        "print(padded_sent)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0 29 35 15 36 40]\n",
            " [ 0  0 32 35 31 20]\n",
            " [ 0  0 26 35 23 47]\n",
            " [ 0  0  0 20 35 14]\n",
            " [ 0  0 19 35 22 44]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMM7d7PRFSMZ"
      },
      "source": [
        "mymodel = Sequential()\n",
        "mymodel.add(Embedding(vocab_size,8,input_length = 6))\n",
        "mymodel.add(Flatten())\n",
        "mymodel.add(Dense(1,activation = 'sigmoid')) #Because target is categorical in nature"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy5FLKj5Fmfb"
      },
      "source": [
        "mymodel.compile(optimizer='adam',loss = 'binary_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmjLkRidFq3h",
        "outputId": "a2dd1093-0198-4247-ed8f-42582bd3198b"
      },
      "source": [
        "mymodel.fit(padded_sent,sent_labels,epochs = 33)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/33\n",
            "1/1 [==============================] - 14s 14s/step - loss: 0.7052 - accuracy: 0.4000\n",
            "Epoch 2/33\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7022 - accuracy: 0.4000\n",
            "Epoch 3/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6992 - accuracy: 0.4000\n",
            "Epoch 4/33\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6961 - accuracy: 0.4000\n",
            "Epoch 5/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.4000\n",
            "Epoch 6/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.4000\n",
            "Epoch 7/33\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6872 - accuracy: 0.4000\n",
            "Epoch 8/33\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6843 - accuracy: 0.4000\n",
            "Epoch 9/33\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6813 - accuracy: 0.4000\n",
            "Epoch 10/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6784 - accuracy: 0.6000\n",
            "Epoch 11/33\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6755 - accuracy: 0.6000\n",
            "Epoch 12/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6726 - accuracy: 0.6000\n",
            "Epoch 13/33\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6697 - accuracy: 0.6000\n",
            "Epoch 14/33\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6668 - accuracy: 0.6000\n",
            "Epoch 15/33\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.6000\n",
            "Epoch 16/33\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6610 - accuracy: 0.8000\n",
            "Epoch 17/33\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6581 - accuracy: 0.8000\n",
            "Epoch 18/33\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.8000\n",
            "Epoch 19/33\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.8000\n",
            "Epoch 20/33\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.8000\n",
            "Epoch 21/33\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.8000\n",
            "Epoch 22/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6436 - accuracy: 0.8000\n",
            "Epoch 23/33\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6407 - accuracy: 0.8000\n",
            "Epoch 24/33\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 1.0000\n",
            "Epoch 25/33\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6349 - accuracy: 1.0000\n",
            "Epoch 26/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6319 - accuracy: 1.0000\n",
            "Epoch 27/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6290 - accuracy: 1.0000\n",
            "Epoch 28/33\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6260 - accuracy: 1.0000\n",
            "Epoch 29/33\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6231 - accuracy: 1.0000\n",
            "Epoch 30/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6201 - accuracy: 1.0000\n",
            "Epoch 31/33\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6170 - accuracy: 1.0000\n",
            "Epoch 32/33\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6140 - accuracy: 1.0000\n",
            "Epoch 33/33\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6110 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f367998f3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pakIasevF6ZR"
      },
      "source": [
        "**EVALUATION:- TEST ACCURACY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9JMnTHeFvN4",
        "outputId": "c06faa68-9711-4ce8-bd68-85d1f8b7cff5"
      },
      "source": [
        "mymodel.evaluate(padded_sent,sent_labels,verbose = 1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6079 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6079109311103821, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-mvX8OjGEeT",
        "outputId": "e50e141e-2bec-405d-ae1f-3eb0f173dfaf"
      },
      "source": [
        "model_loss,model_accuracy = mymodel.evaluate(padded_sent,sent_labels,verbose = 1)\n",
        "print('Accuracy : %f' %(model_accuracy*100))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6079 - accuracy: 1.0000\n",
            "Accuracy : 100.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFoVRQbnGmkk"
      },
      "source": [
        "**THE PREDICTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxZJUTD4Gj4c"
      },
      "source": [
        "sent_for_pred = ['Mobile is awesome machine',\n",
        "                 'Battery is insane']"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oMSlI1FGrqo",
        "outputId": "7690d2b3-764e-4a34-e3d3-2ae9ed118b32"
      },
      "source": [
        "vocab_size = 50 #Is it dimension?\n",
        "encoded = [one_hot(i,vocab_size)for i in sent_for_pred]\n",
        "encoded"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[32, 35, 31, 20], [20, 35, 14]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNjiJkKVG8Ta",
        "outputId": "d7369d48-e8f5-46d3-9a05-462e016159f0"
      },
      "source": [
        "padded_sent = pad_sequences(encoded,maxlen = 6,padding='pre')\n",
        "print(padded_sent)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0 32 35 31 20]\n",
            " [ 0  0  0 20 35 14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp7M6w5SHHP-",
        "outputId": "1b4933d1-9eb9-471a-e8df-71a5e3be2b0d"
      },
      "source": [
        "mymodel.predict_classes(padded_sent)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBjAxLmIIV0-"
      },
      "source": [
        "**TAKE AWAY FROM ABOVE CODE**\n",
        "Here vocabulary is so less, that predictions will not be upto the mark., thus we NEED TO IMPORT VOCABULARY PACKAGES FROM INTERNET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2iVDKnbIqr0"
      },
      "source": [
        "**1. USE PRETRAINNED WORD2VEC MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuNbPBQtHH5u"
      },
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLl_gmXjJLu2"
      },
      "source": [
        "# DONWLOAD PRETRAINNED VOCABULARY\n",
        "pretrained_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbWmVPcTJJSE"
      },
      "source": [
        "pretrained_model.most_similar('data')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}